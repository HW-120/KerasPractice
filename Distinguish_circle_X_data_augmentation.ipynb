{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단순 Circle 모양과 X 모양을 구분해내는 프로그램\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "# 이미지를 감지하기 위한 클래스인 ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "# 총 40개의 훈련셋이 들어있는 경로와 크기를 확인하고\n",
    "# 배치 사이즈는 4로 하여 총 5번 수행하면 한 epoch가 수행됨\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                'circle_X/train',\n",
    "                                target_size=(25, 25), \n",
    "                                batch_size = 2,\n",
    "                                class_mode = 'binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                'circle_X/test',\n",
    "                                target_size = (25, 25),\n",
    "                                batch_size = 2,\n",
    "                                class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 필터 수를 32, 64, 128로 늘려감 \n",
    "# 중간 레이어가 3*3을 고정하여 만듦, 인풋 이미지 사이즈는 25*25이고, RGB라서 3으로(RGB는 필요 없지만)\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(24, 24, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# 핵심 부분만 선정하는 MaxPooling2D로 1/2 해 줌\n",
    "model.add(MaxPooling2D(2))\n",
    "# 한 줄로 줄세우고\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# 최종적으로 둘 중에 분류하는 것이므로 0.5 이상 미만으로 나눔\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 22, 22, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 838,849\n",
      "Trainable params: 838,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 개를 비교하므로 이진 분류를 이용함\n",
    "# 가장 대중적인 adam 최적화 기법을 사용함\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-823de02ac137>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/30\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.5585 - accuracy: 0.6000 - val_loss: 0.4267 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1459 - accuracy: 0.9250 - val_loss: 0.7193 - val_accuracy: 0.7000\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0399 - accuracy: 0.9750 - val_loss: 0.8712 - val_accuracy: 0.7000\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9249 - val_accuracy: 0.7000\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.7000\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 7.0519e-04 - accuracy: 1.0000 - val_loss: 1.0673 - val_accuracy: 0.7000\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.4269e-04 - accuracy: 1.0000 - val_loss: 1.1730 - val_accuracy: 0.7000\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.0975e-04 - accuracy: 1.0000 - val_loss: 1.1725 - val_accuracy: 0.7000\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.9188e-04 - accuracy: 1.0000 - val_loss: 1.1418 - val_accuracy: 0.7000\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.4473e-04 - accuracy: 1.0000 - val_loss: 1.1728 - val_accuracy: 0.7000\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1059e-04 - accuracy: 1.0000 - val_loss: 1.1985 - val_accuracy: 0.7000\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 8.9079e-05 - accuracy: 1.0000 - val_loss: 1.2604 - val_accuracy: 0.7000\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 7.0959e-05 - accuracy: 1.0000 - val_loss: 1.2888 - val_accuracy: 0.7000\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 5.8640e-05 - accuracy: 1.0000 - val_loss: 1.2768 - val_accuracy: 0.7000\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.1173e-05 - accuracy: 1.0000 - val_loss: 1.2759 - val_accuracy: 0.7000\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.4491e-05 - accuracy: 1.0000 - val_loss: 1.3267 - val_accuracy: 0.7000\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.7417e-05 - accuracy: 1.0000 - val_loss: 1.3350 - val_accuracy: 0.7000\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 3.2656e-05 - accuracy: 1.0000 - val_loss: 1.3614 - val_accuracy: 0.7000\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.8763e-05 - accuracy: 1.0000 - val_loss: 1.3577 - val_accuracy: 0.7000\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.5744e-05 - accuracy: 1.0000 - val_loss: 1.3828 - val_accuracy: 0.7000\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2454e-05 - accuracy: 1.0000 - val_loss: 1.3873 - val_accuracy: 0.7000\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0232e-05 - accuracy: 1.0000 - val_loss: 1.3962 - val_accuracy: 0.7000\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.8355e-05 - accuracy: 1.0000 - val_loss: 1.4134 - val_accuracy: 0.7000\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.6574e-05 - accuracy: 1.0000 - val_loss: 1.4318 - val_accuracy: 0.7000\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.5064e-05 - accuracy: 1.0000 - val_loss: 1.4368 - val_accuracy: 0.7000\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.4040e-05 - accuracy: 1.0000 - val_loss: 1.4497 - val_accuracy: 0.7000\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2823e-05 - accuracy: 1.0000 - val_loss: 1.4416 - val_accuracy: 0.6500\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 1.1740e-05 - accuracy: 1.0000 - val_loss: 1.4736 - val_accuracy: 0.6500\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0719e-05 - accuracy: 1.0000 - val_loss: 1.4729 - val_accuracy: 0.6500\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 9.9189e-06 - accuracy: 1.0000 - val_loss: 1.4796 - val_accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "# batch_size가 2이므로 훈련 개수에 따라 에폭시를 20, 10으로 결정함\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=20,\n",
    "        epochs=30,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.4% 확률로 원\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACcAAAAmCAIAAADInRXHAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAIlSURBVFhH1Zc9ksIwDIXDVtBRUsJNKCkpOQIlJR0l3IASbsExOA502ZdIeBRZchyH2Zn9Gowt+/n5P5O6rqs/54d//5b/qXq/31er1cQC+SjlOAXmtYzb7bZcLrkVh+l0ijCuIOioPh6P9XptxkkQ1qsXgDBXE3RUF4sFxSWEUTSfz6lFYrfbvV4vLv5wPp+5uKqQ5twPHVXoUZzZwdiiqRc4HA4UFtvoqCY6CEllcb/fc5kDOuTZ0KtJdpCzIsm0RYm0Ie1qVdlBsqskey0qTLtaFUi7x+NxjCQwZ81QlXYlBZJEPGuGKpAdJIolAWxwK59Dyb1zZrPZ+/3mP200p4rAAUkJasc9h0+nE6e+QZiyy+XS/DSGHbx1X4Ca2p5bPYwMouX0DAWThSmjNBRzbzpU48EpQm+Kxr8PB7Wg5phx5lZaxdwRJsaMs1zGw94SGGf3eTCEAauJtm+x3RKvYfuOXFYMlD1w23BQG5a4pXOguqBJU5YJPWgI/JW3AhIUkw9VBE2asmKk0XD0m9dWJlwtraqMBuQ4X69Xzs2AaoEmTVkxYTDVHSfHGWCVcUEfXCGtSoNpXqvq9s0U5ui0aho43mw23ExVPZ9PLnBQ26FQFUAYHwrU0Ha75VwHtUrKVQEscku+XbiUb3easlGqAC6pOdMuDhP1kKb8sarSrjywlEUg3+5jVYE8sCAM4i8+tRe+oKo2ksL8PPmCKvCEze1e1/UvHWvj6IbaTFkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from IPython.display import Image\n",
    "\n",
    "# 임의로 그린 동그라미와 엑스 중 애매한 그림을 보여줬을 때 반응 확인\n",
    "img = load_img('1.png', target_size=(24, 24, 3))\n",
    "x = img_to_array(img)\n",
    "\n",
    "x = x.reshape((1,) + x.shape)\n",
    "x /= 255\n",
    "\n",
    "y = model.predict(x)[0][0]\n",
    "y = round(float(y), 3)\n",
    "\n",
    "if y > 0.5:\n",
    "    print(str(y*100) + \"% 확률로 원\")\n",
    "else:\n",
    "    print(str((1-y) * 100) + \"% 확률로 엑스\")\n",
    "Image(filename='1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 이미지 데이터를 이리저리 굴리면서 추가로 학습해주자\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# 만약 위 datagen을 사용하게 되면 아래 처럼 그림을 바꿔가며 생성해줌\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "img = load_img('1.png', target_size=(25, 25))\n",
    "x = img_to_array(img)\n",
    "print(type(x))\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "i = 0;\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.axis('off')  # 불필요한 그래프 틀과 라벨 없애기\n",
    "    imgplot = plt.imshow(array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 5 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터셋을 실제로 섞어보자\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=40,      # 랜덤으로 돌리기\n",
    "    width_shift_range=0.2,  # 이동시키기\n",
    "    height_shift_range=0.2, # 이동시키기\n",
    "    shear_range=0.2,  # 기울이기\n",
    "    zoom_range=0.2,   # 확대 축소하기\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'circle_X/train',\n",
    "    target_size=(25, 25),\n",
    "    batch_size=2,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generattor = val_datagen.flow_from_directory(\n",
    "    'circle_X/test',\n",
    "    target_size=(25, 25),\n",
    "    batch_size=2,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 22, 22, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 838,849\n",
      "Trainable params: 838,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2992 - accuracy: 0.5750 - val_loss: 0.6061 - val_accuracy: 0.6000\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5258 - accuracy: 0.8250 - val_loss: 0.6690 - val_accuracy: 0.6500\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5939 - accuracy: 0.7250 - val_loss: 0.6327 - val_accuracy: 0.7000\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4734 - accuracy: 0.8250 - val_loss: 0.5741 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6795 - accuracy: 0.6250 - val_loss: 0.5599 - val_accuracy: 0.6000\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5004 - accuracy: 0.7000 - val_loss: 0.4872 - val_accuracy: 0.6500\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.5014 - accuracy: 0.7750 - val_loss: 0.4256 - val_accuracy: 0.8000\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.3277 - accuracy: 0.9000 - val_loss: 0.6115 - val_accuracy: 0.7000\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6664 - accuracy: 0.7250 - val_loss: 0.3975 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.4231 - accuracy: 0.8000 - val_loss: 0.4498 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.4099 - accuracy: 0.8000 - val_loss: 0.3174 - val_accuracy: 0.8000\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.3281 - accuracy: 0.8250 - val_loss: 0.3601 - val_accuracy: 0.8000\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.2705 - accuracy: 0.8500 - val_loss: 0.3229 - val_accuracy: 0.8000\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4409 - accuracy: 0.8000 - val_loss: 0.2575 - val_accuracy: 0.9000\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.2569 - accuracy: 0.9000 - val_loss: 0.3672 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.1505 - accuracy: 0.9250 - val_loss: 0.4169 - val_accuracy: 0.7000\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5142 - accuracy: 0.8250 - val_loss: 0.3117 - val_accuracy: 0.8000\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1662 - accuracy: 0.9250 - val_loss: 0.5224 - val_accuracy: 0.8000\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.2713 - accuracy: 0.8500 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.1260 - accuracy: 0.9500 - val_loss: 0.4408 - val_accuracy: 0.8000\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.3402 - accuracy: 0.8750 - val_loss: 0.4059 - val_accuracy: 0.8500\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.3910 - accuracy: 0.8500 - val_loss: 0.5878 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.2716 - accuracy: 0.9000 - val_loss: 0.4136 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.2597 - accuracy: 0.9000 - val_loss: 0.3262 - val_accuracy: 0.9000\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.3130 - accuracy: 0.9000 - val_loss: 0.3546 - val_accuracy: 0.8000\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.2882 - accuracy: 0.8500 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.2669 - accuracy: 0.8750 - val_loss: 0.2663 - val_accuracy: 0.9500\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.2300 - accuracy: 0.9250 - val_loss: 0.2906 - val_accuracy: 0.8500\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.1985 - accuracy: 0.9750 - val_loss: 0.2155 - val_accuracy: 0.9000\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# 다시 새로 학습해준다\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=20,\n",
    "        epochs=30,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% 확률로 원\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACcAAAAmCAIAAADInRXHAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAIlSURBVFhH1Zc9ksIwDIXDVtBRUsJNKCkpOQIlJR0l3IASbsExOA502ZdIeBRZchyH2Zn9Gowt+/n5P5O6rqs/54d//5b/qXq/31er1cQC+SjlOAXmtYzb7bZcLrkVh+l0ijCuIOioPh6P9XptxkkQ1qsXgDBXE3RUF4sFxSWEUTSfz6lFYrfbvV4vLv5wPp+5uKqQ5twPHVXoUZzZwdiiqRc4HA4UFtvoqCY6CEllcb/fc5kDOuTZ0KtJdpCzIsm0RYm0Ie1qVdlBsqskey0qTLtaFUi7x+NxjCQwZ81QlXYlBZJEPGuGKpAdJIolAWxwK59Dyb1zZrPZ+/3mP200p4rAAUkJasc9h0+nE6e+QZiyy+XS/DSGHbx1X4Ca2p5bPYwMouX0DAWThSmjNBRzbzpU48EpQm+Kxr8PB7Wg5phx5lZaxdwRJsaMs1zGw94SGGf3eTCEAauJtm+x3RKvYfuOXFYMlD1w23BQG5a4pXOguqBJU5YJPWgI/JW3AhIUkw9VBE2asmKk0XD0m9dWJlwtraqMBuQ4X69Xzs2AaoEmTVkxYTDVHSfHGWCVcUEfXCGtSoNpXqvq9s0U5ui0aho43mw23ExVPZ9PLnBQ26FQFUAYHwrU0Ha75VwHtUrKVQEscku+XbiUb3easlGqAC6pOdMuDhP1kKb8sarSrjywlEUg3+5jVYE8sCAM4i8+tRe+oKo2ksL8PPmCKvCEze1e1/UvHWvj6IbaTFkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 재학습된 모델에 아까 79.4%가 나온 원을 넣었을 때 100%로 상승한 것을 볼 수 있다\n",
    "img = load_img('1.png', target_size=(24, 24, 3))\n",
    "x = img_to_array(img)\n",
    "\n",
    "x = x.reshape((1,) + x.shape)\n",
    "x /= 255\n",
    "\n",
    "y = model.predict(x)[0][0]\n",
    "y = round(float(y), 3)\n",
    "\n",
    "if y > 0.5:\n",
    "    print(str(y*100) + \"% 확률로 원\")\n",
    "else:\n",
    "    print(str((1-y) * 100) + \"% 확률로 엑스\")\n",
    "Image(filename='1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
