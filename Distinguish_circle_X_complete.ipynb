{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단순 Circle 모양과 X 모양을 구분해내는 프로그램\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "# 이미지를 감지하기 위한 클래스인 ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "# 총 40개의 훈련셋이 들어있는 경로와 크기를 확인하고\n",
    "# 배치 사이즈는 4로 하여 총 5번 수행하면 한 epoch가 수행됨\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                'circle_X/train',\n",
    "                                target_size=(25, 25), \n",
    "                                batch_size = 2,\n",
    "                                class_mode = 'binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                'circle_X/test',\n",
    "                                target_size = (25, 25),\n",
    "                                batch_size = 2,\n",
    "                                class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(24, 24, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 22, 22, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 838,849\n",
      "Trainable params: 838,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-823de02ac137>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/30\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.5585 - accuracy: 0.6000 - val_loss: 0.4267 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.1459 - accuracy: 0.9250 - val_loss: 0.7193 - val_accuracy: 0.7000\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0399 - accuracy: 0.9750 - val_loss: 0.8712 - val_accuracy: 0.7000\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9249 - val_accuracy: 0.7000\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.7000\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 7.0519e-04 - accuracy: 1.0000 - val_loss: 1.0673 - val_accuracy: 0.7000\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.4269e-04 - accuracy: 1.0000 - val_loss: 1.1730 - val_accuracy: 0.7000\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 3.0975e-04 - accuracy: 1.0000 - val_loss: 1.1725 - val_accuracy: 0.7000\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.9188e-04 - accuracy: 1.0000 - val_loss: 1.1418 - val_accuracy: 0.7000\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.4473e-04 - accuracy: 1.0000 - val_loss: 1.1728 - val_accuracy: 0.7000\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.1059e-04 - accuracy: 1.0000 - val_loss: 1.1985 - val_accuracy: 0.7000\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 8.9079e-05 - accuracy: 1.0000 - val_loss: 1.2604 - val_accuracy: 0.7000\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 7.0959e-05 - accuracy: 1.0000 - val_loss: 1.2888 - val_accuracy: 0.7000\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 5.8640e-05 - accuracy: 1.0000 - val_loss: 1.2768 - val_accuracy: 0.7000\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.1173e-05 - accuracy: 1.0000 - val_loss: 1.2759 - val_accuracy: 0.7000\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 4.4491e-05 - accuracy: 1.0000 - val_loss: 1.3267 - val_accuracy: 0.7000\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 3.7417e-05 - accuracy: 1.0000 - val_loss: 1.3350 - val_accuracy: 0.7000\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 3.2656e-05 - accuracy: 1.0000 - val_loss: 1.3614 - val_accuracy: 0.7000\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.8763e-05 - accuracy: 1.0000 - val_loss: 1.3577 - val_accuracy: 0.7000\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.5744e-05 - accuracy: 1.0000 - val_loss: 1.3828 - val_accuracy: 0.7000\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2454e-05 - accuracy: 1.0000 - val_loss: 1.3873 - val_accuracy: 0.7000\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0232e-05 - accuracy: 1.0000 - val_loss: 1.3962 - val_accuracy: 0.7000\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.8355e-05 - accuracy: 1.0000 - val_loss: 1.4134 - val_accuracy: 0.7000\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.6574e-05 - accuracy: 1.0000 - val_loss: 1.4318 - val_accuracy: 0.7000\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 1.5064e-05 - accuracy: 1.0000 - val_loss: 1.4368 - val_accuracy: 0.7000\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 1.4040e-05 - accuracy: 1.0000 - val_loss: 1.4497 - val_accuracy: 0.7000\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.2823e-05 - accuracy: 1.0000 - val_loss: 1.4416 - val_accuracy: 0.6500\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 1.1740e-05 - accuracy: 1.0000 - val_loss: 1.4736 - val_accuracy: 0.6500\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 1.0719e-05 - accuracy: 1.0000 - val_loss: 1.4729 - val_accuracy: 0.6500\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 9.9189e-06 - accuracy: 1.0000 - val_loss: 1.4796 - val_accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=20,\n",
    "        epochs=30,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.4% 확률로 원\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACcAAAAmCAIAAADInRXHAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAAIlSURBVFhH1Zc9ksIwDIXDVtBRUsJNKCkpOQIlJR0l3IASbsExOA502ZdIeBRZchyH2Zn9Gowt+/n5P5O6rqs/54d//5b/qXq/31er1cQC+SjlOAXmtYzb7bZcLrkVh+l0ijCuIOioPh6P9XptxkkQ1qsXgDBXE3RUF4sFxSWEUTSfz6lFYrfbvV4vLv5wPp+5uKqQ5twPHVXoUZzZwdiiqRc4HA4UFtvoqCY6CEllcb/fc5kDOuTZ0KtJdpCzIsm0RYm0Ie1qVdlBsqskey0qTLtaFUi7x+NxjCQwZ81QlXYlBZJEPGuGKpAdJIolAWxwK59Dyb1zZrPZ+/3mP200p4rAAUkJasc9h0+nE6e+QZiyy+XS/DSGHbx1X4Ca2p5bPYwMouX0DAWThSmjNBRzbzpU48EpQm+Kxr8PB7Wg5phx5lZaxdwRJsaMs1zGw94SGGf3eTCEAauJtm+x3RKvYfuOXFYMlD1w23BQG5a4pXOguqBJU5YJPWgI/JW3AhIUkw9VBE2asmKk0XD0m9dWJlwtraqMBuQ4X69Xzs2AaoEmTVkxYTDVHSfHGWCVcUEfXCGtSoNpXqvq9s0U5ui0aho43mw23ExVPZ9PLnBQ26FQFUAYHwrU0Ha75VwHtUrKVQEscku+XbiUb3easlGqAC6pOdMuDhP1kKb8sarSrjywlEUg3+5jVYE8sCAM4i8+tRe+oKo2ksL8PPmCKvCEze1e1/UvHWvj6IbaTFkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from IPython.display import Image\n",
    "\n",
    "img = load_img('1.png', target_size=(24, 24, 3))\n",
    "x = img_to_array(img)\n",
    "\n",
    "x = x.reshape((1,) + x.shape)\n",
    "x /= 255\n",
    "\n",
    "y = model.predict(x)[0][0]\n",
    "y = round(float(y), 3)\n",
    "\n",
    "if y > 0.5:\n",
    "    print(str(y*100) + \"% 확률로 원\")\n",
    "else:\n",
    "    print(str((1-y) * 100) + \"% 확률로 엑스\")\n",
    "Image(filename='1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
